{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b29cb9f2-e3c0-44cc-8327-7757c5add287",
   "metadata": {},
   "source": [
    "# Setup\n",
    "\n",
    "Install all needed dependencies."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "bff9c793-7ca5-4f3b-8353-b55d3acb3b4e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "codeflare-sdk 0.26.0 requires pydantic<2, but you have pydantic 2.11.1 which is incompatible.\n",
      "kfp 2.9.0 requires requests-toolbelt<1,>=0.8.0, but you have requests-toolbelt 1.0.0 which is incompatible.\u001b[0m\u001b[31m\n",
      "\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m24.2\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m25.0.1\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip install --quiet --upgrade langchain_community langchain-huggingface langchain-openai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7ac090bc-a3fa-4bd3-a385-ff597777a8e7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m24.2\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m25.0.1\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "# Install the YAML magic\n",
    "!pip install --quiet yamlmagic\n",
    "%load_ext yamlmagic"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1918ea4-87c8-4880-900a-134a0bbb5591",
   "metadata": {},
   "source": [
    "Configuration and used models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3f0abf06-145f-4644-b25d-823c6ffc58af",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            require(\n",
       "                [\n",
       "                    \"notebook/js/codecell\",\n",
       "                    \"codemirror/mode/yaml/yaml\"\n",
       "                ],\n",
       "                function(cc){\n",
       "                    cc.CodeCell.options_default.highlight_modes.magic_yaml = {\n",
       "                        reg: [\"^%%yaml\"]\n",
       "                    }\n",
       "                }\n",
       "            );\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%%yaml parameters\n",
    "\n",
    "# Model\n",
    "embedder_model_name_or_path: ibm-granite/granite-embedding-30m-english\n",
    "generator_model_name_or_path: ibm-granite/granite-3.2-2b-instruct"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24ef69a7-c616-4b06-b1ad-d3cb98abe7df",
   "metadata": {},
   "source": [
    "#  Langchain RAG\n",
    "\n",
    "Prepare list of documents containing chunks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "cb54a2f0-aef6-4308-a8b4-07e9c7cca23b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 150 entries\n"
     ]
    }
   ],
   "source": [
    "import urllib.request\n",
    "from langchain_core.documents import Document\n",
    "\n",
    "\n",
    "link = \"https://huggingface.co/ngxson/demo_simple_rag_py/raw/main/cat-facts.txt\"\n",
    "documents = []\n",
    "\n",
    "# Retrieve knowledge from provided link, use every line as a separate chunk.\n",
    "for line in urllib.request.urlopen(link):\n",
    "    documents.append(\n",
    "        Document(\n",
    "            page_content=line.decode('utf-8'),\n",
    "            metadata={\"source\": \"cats\", \"doc_id\": \"cats\"}\n",
    "        )\n",
    "    )\n",
    "\n",
    "print(f'Loaded {len(documents)} entries')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7676b550-1247-4c90-aa0d-44ca9561a6d9",
   "metadata": {},
   "source": [
    "Initialize vector store and fill it with chunks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "286c9e72-c921-489a-b977-8df7d964ba26",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.vectorstores import InMemoryVectorStore\n",
    "from langchain_huggingface import HuggingFaceEmbeddings\n",
    "\n",
    "\n",
    "embeddings = HuggingFaceEmbeddings(\n",
    "    model_name=parameters['embedder_model_name_or_path'],\n",
    ")\n",
    "vector_store = InMemoryVectorStore(embeddings)\n",
    "document_ids = vector_store.add_documents(documents=documents)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc5bb3cd-9785-43fa-b1c4-e16e78b69073",
   "metadata": {},
   "source": [
    "**Specify user query here**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9dc40487-bf1c-49ed-9106-0dc46e38820c",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_query = \"tell me about cat mummies\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "677c95fe-1d36-4dfe-bf0d-1283857e5ee7",
   "metadata": {},
   "source": [
    "Use similarity search to retrieve most related chunks from vector database."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3c118e29-7fbf-4741-a474-3e5a3d46d8c1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Retrieved knowledge:\n",
      "page_content='In ancient Egypt, mummies were made of cats, and embalmed mice were placed with them in their tombs. In one ancient city, over 300,000 cat mummies were found.\n",
      "' metadata={'source': 'cats', 'doc_id': 'cats'}\n",
      "page_content='In 1888, more than 300,000 mummified cats were found an Egyptian cemetery. They were stripped of their wrappings and carted off to be used by farmers in England and the U.S. for fertilizer.\n",
      "' metadata={'source': 'cats', 'doc_id': 'cats'}\n",
      "page_content='When a family cat died in ancient Egypt, family members would mourn by shaving off their eyebrows. They also held elaborate funerals during which they drank wine and beat their breasts. The cat was embalmed with a sculpted wooden mask and the tiny mummy was placed in the family tomb or in a pet cemetery with tiny mummies of mice.\n",
      "' metadata={'source': 'cats', 'doc_id': 'cats'}\n",
      "page_content='Mohammed loved cats and reportedly his favorite cat, Muezza, was a tabby. Legend says that tabby cats have an “M” for Mohammed on top of their heads because Mohammad would often rest his hand on the cat’s head.\n",
      "' metadata={'source': 'cats', 'doc_id': 'cats'}\n"
     ]
    }
   ],
   "source": [
    "docs = vector_store.similarity_search(input_query)\n",
    "\n",
    "print('Retrieved knowledge:')\n",
    "for doc in docs:\n",
    "  print(doc)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b52d2349-02aa-47d6-a5d0-783e8361feee",
   "metadata": {},
   "source": [
    "Generate response for user query using context from dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "8c61b305-5f62-4f99-8577-0708ba5e5f28",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_openai import ChatOpenAI\n",
    "from langchain.prompts import PromptTemplate\n",
    "from langchain.chains.retrieval import create_retrieval_chain\n",
    "from langchain.chains.combine_documents import create_stuff_documents_chain\n",
    "import transformers\n",
    "\n",
    "\n",
    "llm = ChatOpenAI(\n",
    "    model=\"test-model\",\n",
    "    openai_api_key=\"\",\n",
    "    openai_api_base=\"\",\n",
    "    max_tokens=1024,\n",
    "    temperature=0,\n",
    ")\n",
    "\n",
    "tokenizer = transformers.AutoTokenizer.from_pretrained(parameters['generator_model_name_or_path'])\n",
    "if tokenizer.pad_token_id is None:\n",
    "    tokenizer.pad_token_id = tokenizer.eos_token_id\n",
    "\n",
    "# Construct system prompt for inference providing retrieved chunks as context.\n",
    "prompt = tokenizer.apply_chat_template(\n",
    "    conversation=[{\n",
    "        \"role\": \"user\",\n",
    "        \"content\": \"{input}\",\n",
    "    }],\n",
    "    documents=[{\n",
    "        \"title\": \"placeholder\",\n",
    "        \"text\": \"{context}\",\n",
    "    }],\n",
    "    add_generation_prompt=True,\n",
    "    tokenize=False,\n",
    ")\n",
    "prompt_template = PromptTemplate.from_template(template=prompt)\n",
    "\n",
    "# Wrap retrieved chunks using prompt template\n",
    "document_prompt_template = PromptTemplate.from_template(template=\"\"\"\\\n",
    "Document {doc_id}\n",
    "{page_content}\"\"\")\n",
    "document_separator=\"\\n\\n\"\n",
    "\n",
    "# Create retrieval chain\n",
    "combine_docs_chain = create_stuff_documents_chain(\n",
    "    llm=llm,\n",
    "    prompt=prompt_template,\n",
    "    document_prompt=document_prompt_template,\n",
    "    document_separator=document_separator,\n",
    ")\n",
    "rag_chain = create_retrieval_chain(\n",
    "    retriever=vector_store.as_retriever(),\n",
    "    combine_docs_chain=combine_docs_chain,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "825212b5-0f8a-4743-9ab5-a06a76915587",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cat mummies have a significant historical and cultural presence, particularly in ancient Egypt. Here are some key points:\n",
      "\n",
      "1. **Ancient Egyptian Practice**: In ancient Egypt, cats were mummified as part of their funeral rituals. The mummification process involved embalming the cat with a sculpted wooden mask, creating a tiny mummy.\n",
      "\n",
      "2. **Embalmed Cats in Tomb and Pet Cemeteries**: The embalmed cat mummies were often placed in family tombs or in pet cemeteries, sometimes alongside tiny mummies of mice. This practice suggests a deep connection between cats and their owners, possibly symbolizing the cat's role in protecting the deceased in the afterlife.\n",
      "\n",
      "3. **Mass Mummification**: In 1888, over 300,000 cat mummies were discovered in an Egyptian cemetery. These were stripped of their wrappings and exported to England and the U.S. for use as fertilizer, indicating the high value placed on cat mummies in ancient times.\n",
      "\n",
      "4. **Cultural Significance**: The mourning rituals of ancient Egyptians involved shaving eyebrows and holding elaborate funerals for cats. They also drank wine and beat their breasts during these ceremonies, reflecting the emotional attachment to their feline companions.\n",
      "\n",
      "5. **Mohammed and Tabby Cats**: According to legend, Prophet Mohammed, Mohammed, had a favorite cat named Muezza, who was a tabby. The story goes that tabby cats have an \"M\" on their heads because Mohammed would often rest his hand on the cat's head, leaving an imprint.\n",
      "\n",
      "These accounts highlight the importance of cats in ancient Egyptian culture, their role in funeral rituals, and the enduring legacy of cat mummies in both historical and contemporary contexts.\n"
     ]
    }
   ],
   "source": [
    "output = rag_chain.invoke({\"input\": input_query})\n",
    "\n",
    "print(output['answer'])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.11",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
