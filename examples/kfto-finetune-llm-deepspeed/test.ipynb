{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e7957be7-bf5e-40ab-9d88-ff0739332051",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting kubeflow-training\n",
      "  Obtaining dependency information for kubeflow-training from https://files.pythonhosted.org/packages/bc/d8/216bcea878fb7b1dcb02b15e6e95564dc45003f4c6e7c241344b93fbf1f6/kubeflow_training-1.9.0-py3-none-any.whl.metadata\n",
      "  Downloading kubeflow_training-1.9.0-py3-none-any.whl.metadata (1.7 kB)\n",
      "Requirement already satisfied: certifi>=14.05.14 in /opt/app-root/lib64/python3.11/site-packages (from kubeflow-training) (2024.8.30)\n",
      "Requirement already satisfied: six>=1.10 in /opt/app-root/lib64/python3.11/site-packages (from kubeflow-training) (1.16.0)\n",
      "Requirement already satisfied: setuptools>=21.0.0 in /opt/app-root/lib64/python3.11/site-packages (from kubeflow-training) (74.1.3)\n",
      "Requirement already satisfied: urllib3>=1.15.1 in /opt/app-root/lib64/python3.11/site-packages (from kubeflow-training) (1.26.20)\n",
      "Collecting kubernetes>=27.2.0 (from kubeflow-training)\n",
      "  Obtaining dependency information for kubernetes>=27.2.0 from https://files.pythonhosted.org/packages/df/14/a59acfe4b3095f2a4fd8d13b348853a69c8f1ed4bce9af00d1b31351a88e/kubernetes-32.0.0-py2.py3-none-any.whl.metadata\n",
      "  Downloading kubernetes-32.0.0-py2.py3-none-any.whl.metadata (1.5 kB)\n",
      "Collecting retrying>=1.3.3 (from kubeflow-training)\n",
      "  Obtaining dependency information for retrying>=1.3.3 from https://files.pythonhosted.org/packages/8f/04/9e36f28be4c0532c0e9207ff9dc01fb13a2b0eb036476a213b0000837d0e/retrying-1.3.4-py3-none-any.whl.metadata\n",
      "  Downloading retrying-1.3.4-py3-none-any.whl.metadata (6.9 kB)\n",
      "Requirement already satisfied: python-dateutil>=2.5.3 in /opt/app-root/lib64/python3.11/site-packages (from kubernetes>=27.2.0->kubeflow-training) (2.9.0.post0)\n",
      "Requirement already satisfied: pyyaml>=5.4.1 in /opt/app-root/lib64/python3.11/site-packages (from kubernetes>=27.2.0->kubeflow-training) (6.0.2)\n",
      "Requirement already satisfied: google-auth>=1.0.1 in /opt/app-root/lib64/python3.11/site-packages (from kubernetes>=27.2.0->kubeflow-training) (2.36.0)\n",
      "Requirement already satisfied: websocket-client!=0.40.0,!=0.41.*,!=0.42.*,>=0.32.0 in /opt/app-root/lib64/python3.11/site-packages (from kubernetes>=27.2.0->kubeflow-training) (1.8.0)\n",
      "Requirement already satisfied: requests in /opt/app-root/lib64/python3.11/site-packages (from kubernetes>=27.2.0->kubeflow-training) (2.32.3)\n",
      "Requirement already satisfied: requests-oauthlib in /opt/app-root/lib64/python3.11/site-packages (from kubernetes>=27.2.0->kubeflow-training) (2.0.0)\n",
      "Requirement already satisfied: oauthlib>=3.2.2 in /opt/app-root/lib64/python3.11/site-packages (from kubernetes>=27.2.0->kubeflow-training) (3.2.2)\n",
      "Collecting durationpy>=0.7 (from kubernetes>=27.2.0->kubeflow-training)\n",
      "  Obtaining dependency information for durationpy>=0.7 from https://files.pythonhosted.org/packages/4c/a3/ac312faeceffd2d8f86bc6dcb5c401188ba5a01bc88e69bed97578a0dfcd/durationpy-0.9-py3-none-any.whl.metadata\n",
      "  Downloading durationpy-0.9-py3-none-any.whl.metadata (338 bytes)\n",
      "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /opt/app-root/lib64/python3.11/site-packages (from google-auth>=1.0.1->kubernetes>=27.2.0->kubeflow-training) (5.5.0)\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in /opt/app-root/lib64/python3.11/site-packages (from google-auth>=1.0.1->kubernetes>=27.2.0->kubeflow-training) (0.4.1)\n",
      "Requirement already satisfied: rsa<5,>=3.1.4 in /opt/app-root/lib64/python3.11/site-packages (from google-auth>=1.0.1->kubernetes>=27.2.0->kubeflow-training) (4.9)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /opt/app-root/lib64/python3.11/site-packages (from requests->kubernetes>=27.2.0->kubeflow-training) (3.4.0)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/app-root/lib64/python3.11/site-packages (from requests->kubernetes>=27.2.0->kubeflow-training) (3.10)\n",
      "Requirement already satisfied: pyasn1<0.7.0,>=0.4.6 in /opt/app-root/lib64/python3.11/site-packages (from pyasn1-modules>=0.2.1->google-auth>=1.0.1->kubernetes>=27.2.0->kubeflow-training) (0.6.1)\n",
      "Downloading kubeflow_training-1.9.0-py3-none-any.whl (111 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m111.2/111.2 kB\u001b[0m \u001b[31m6.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading kubernetes-32.0.0-py2.py3-none-any.whl (2.0 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.0/2.0 MB\u001b[0m \u001b[31m70.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading retrying-1.3.4-py3-none-any.whl (11 kB)\n",
      "Downloading durationpy-0.9-py3-none-any.whl (3.5 kB)\n",
      "Installing collected packages: durationpy, retrying, kubernetes, kubeflow-training\n",
      "  Attempting uninstall: kubernetes\n",
      "    Found existing installation: kubernetes 26.1.0\n",
      "    Uninstalling kubernetes-26.1.0:\n",
      "      Successfully uninstalled kubernetes-26.1.0\n",
      "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "codeflare-sdk 0.23.1 requires kubernetes<27,>=25.3.0, but you have kubernetes 32.0.0 which is incompatible.\n",
      "kfp 2.9.0 requires kubernetes<31,>=8.0.0, but you have kubernetes 32.0.0 which is incompatible.\u001b[0m\u001b[31m\n",
      "\u001b[0mSuccessfully installed durationpy-0.9 kubeflow-training-1.9.0 kubernetes-32.0.0 retrying-1.3.4\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m23.2.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m25.0\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install -U kubeflow-training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "a1222715-691b-4f9e-81cf-ac8a4e300831",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_func():\n",
    "    import os\n",
    "    import logging\n",
    "    from transformers import (\n",
    "        AutoModelForCausalLM,\n",
    "        AutoTokenizer,\n",
    "        TrainingArguments,\n",
    "        DataCollatorForLanguageModeling,\n",
    "    )\n",
    "    from trl import SFTTrainer\n",
    "    from datasets import load_dataset\n",
    "    from datasets.distributed import split_dataset_by_node\n",
    "    from peft import LoraConfig, get_peft_model\n",
    "\n",
    "    log_formatter = logging.Formatter(\n",
    "        \"%(asctime)s %(levelname)-8s %(message)s\", \"%Y-%m-%dT%H:%M:%SZ\"\n",
    "    )\n",
    "    logger = logging.getLogger(__file__)\n",
    "    console_handler = logging.StreamHandler()\n",
    "    console_handler.setFormatter(log_formatter)\n",
    "    logger.addHandler(console_handler)\n",
    "    logger.setLevel(logging.INFO)\n",
    "\n",
    "    # Create system prompt\n",
    "    system_message = \"\"\"Solve the given high school math problem by providing a clear explanation of each step leading to the final solution.\n",
    "\n",
    "    Provide a detailed breakdown of your calculations, beginning with an explanation of the problem and describing how you derive each formula, value, or conclusion. Use logical steps that build upon one another, to arrive at the final answer in a systematic manner.\n",
    "\n",
    "    # Steps\n",
    "\n",
    "    1. **Understand the Problem**: Restate the given math problem and clearly identify the main question and any important given values.\n",
    "    2. **Set Up**: Identify the key formulas or concepts that could help solve the problem (e.g., algebraic manipulation, geometry formulas, trigonometric identities).\n",
    "    3. **Solve Step-by-Step**: Iteratively progress through each step of the math problem, justifying why each consecutive operation brings you closer to the solution.\n",
    "    4. **Double Check**: If applicable, double check the work for accuracy and sense, and mention potential alternative approaches if any.\n",
    "    5. **Final Answer**: Provide the numerical or algebraic solution clearly, accompanied by appropriate units if relevant.\n",
    "\n",
    "    # Notes\n",
    "\n",
    "    - Always clearly define any variable or term used.\n",
    "    - Wherever applicable, include unit conversions or context to explain why each formula or step has been chosen.\n",
    "    - Assume the level of mathematics is suitable for high school, and avoid overly advanced math techniques unless they are common at that level.\n",
    "    \"\"\"\n",
    "\n",
    "    model_name = \"meta-llama/Llama-3.2-1B-Instruct\"\n",
    "    model = AutoModelForCausalLM.from_pretrained(\n",
    "        pretrained_model_name_or_path=model_name,\n",
    "    )\n",
    "    tokenizer = AutoTokenizer.from_pretrained(\n",
    "        pretrained_model_name_or_path=model_name,\n",
    "    )\n",
    "    tokenizer.pad_token = tokenizer.eos_token\n",
    "\n",
    "    # Freeze model parameters\n",
    "#    for param in model.parameters():\n",
    "#        param.requires_grad = False\n",
    "\n",
    "    # Inspired by https://medium.com/@alexandros_chariton/how-to-fine-tune-llama-3-2-instruct-on-your-own-data-a-detailed-guide-e5f522f397d7\n",
    "    def format_dataset(example):\n",
    "        messages = [\n",
    "            {\"role\": \"system\", \"content\": system_message},\n",
    "            {\"role\": \"user\", \"content\": example['question']},\n",
    "            {\"role\": \"assistant\", \"content\": example['answer']}\n",
    "        ]\n",
    "        prompt = tokenizer.apply_chat_template(\n",
    "            messages, tokenize=False, add_generation_prompt=False\n",
    "        )\n",
    "        return {\"prompt\": prompt}\n",
    "\n",
    "    def tokenize_dataset(example):\n",
    "        tokens = tokenizer(example['prompt'], padding=\"max_length\")\n",
    "        # Set padding token labels to -100 to ignore them in loss calculation\n",
    "        tokens['labels'] = [\n",
    "            -100 if token == tokenizer.pad_token_id else token for token in tokens['input_ids']\n",
    "        ]\n",
    "        return tokens\n",
    "\n",
    "    dataset = load_dataset(\"openai/gsm8k\", \"main\")\n",
    "    train_data = dataset[\"train\"].map(format_dataset, remove_columns=['question', 'answer'])\n",
    "    eval_data = dataset[\"test\"].map(format_dataset, remove_columns=['question', 'answer'])\n",
    "    print(train_data['prompt'][0])\n",
    "#    train_data = train_data.map(tokenize_dataset, remove_columns=['question', 'answer', 'prompt'])\n",
    "#    eval_data = eval_data.map(tokenize_dataset, remove_columns=['question', 'answer', 'prompt'])\n",
    "\n",
    "#    lora_config = LoraConfig(r=4, lora_alpha=16, lora_dropout=0.1, bias=\"none\")\n",
    "#    model.enable_input_require_grads()\n",
    "#    model = get_peft_model(model, lora_config)\n",
    "\n",
    "    trainer = SFTTrainer(\n",
    "        model=model,\n",
    "        train_dataset=train_data,\n",
    "        eval_dataset=eval_data,\n",
    "        tokenizer=tokenizer,\n",
    "        dataset_text_field=\"prompt\",\n",
    "        args=TrainingArguments(output_dir=\"/tmp\",\n",
    "                               per_device_train_batch_size=1,\n",
    "                               per_device_eval_batch_size=1,\n",
    "                               num_train_epochs=8,\n",
    "                               logging_dir=\"/logs\",\n",
    "                               eval_strategy=\"epoch\",\n",
    "                               save_strategy=\"no\"),\n",
    "    )\n",
    "\n",
    "#    trainer.data_collator = DataCollatorForLanguageModeling(\n",
    "#        tokenizer,\n",
    "#        pad_to_multiple_of=8,\n",
    "#        mlm=False,\n",
    "#    )\n",
    "\n",
    "    # Train and save the model.\n",
    "    trainer.train()\n",
    "    trainer.save_model()\n",
    "    logger.info(\"parallel_mode: '{0}'\".format(trainer.args.parallel_mode))\n",
    "    logger.info(\"is_model_parallel: '{0}'\".format(trainer.is_model_parallel))\n",
    "    logger.info(\"model_wrapped: '{0}'\".format(trainer.model_wrapped))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "11154c3c-7c23-42a7-a3d1-890e4f648e29",
   "metadata": {},
   "outputs": [],
   "source": [
    "from kubeflow.training import TrainingClient"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "ba2fa8dc-9aaf-4c6b-a44f-500f40909f74",
   "metadata": {},
   "outputs": [],
   "source": [
    "from kubernetes.client import (\n",
    "    V1EnvVar,\n",
    "    V1EnvVarSource,\n",
    "    V1SecretKeySelector\n",
    ")\n",
    "\n",
    "TrainingClient().create_job(\n",
    "    job_kind=\"PyTorchJob\",\n",
    "    name=\"pytorch-ddp2\",\n",
    "    train_func=train_func,\n",
    "    num_workers=1,\n",
    "    num_procs_per_worker=\"auto\",\n",
    "    resources_per_worker={\"gpu\": 2},\n",
    "    base_image=\"quay.io/modh/training:py311-cuda121-torch241\",\n",
    "    env_vars=[\n",
    "        V1EnvVar(name=\"HF_TOKEN\", value_from=V1EnvVarSource(secret_key_ref=V1SecretKeySelector(key=\"HF_TOKEN\", name=\"hf-token\"))),\n",
    "        V1EnvVar(name=\"NCCL_DEBUG\", value=\"INFO\"),\n",
    "#        V1EnvVar(name=\"TOKENIZERS_PARALLELISM\", value=\"false\"),\n",
    "    ],\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d731d9d4-d8d4-47a9-b204-497c97b86ddb",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.11",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
